{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Implemnting Decision Tree ID3 Algorithm"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np \r\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "df = pd.read_csv(\"BreastCancer.csv\") #read the data\r\n",
    "df.head() #view the first five rows\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# define function to calculate total entropy\r\n",
    "def calc_total_entropy(train_data, label, class_list):\r\n",
    "    total_row = train_data.shape[0] #the total size of the dataset\r\n",
    "    total_entr = 0\r\n",
    "    \r\n",
    "    for c in class_list: #for each class in the label\r\n",
    "        total_class_count = train_data[train_data[label] == c].shape[0] #number of the class\r\n",
    "        total_class_entr = - (total_class_count/total_row)*np.log2(total_class_count/total_row) #entropy of the class\r\n",
    "        total_entr += total_class_entr #adding the class entropy to the total entropy of the dataset\r\n",
    "    \r\n",
    "    return total_entr"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# define function to calculate entropy for specific feature \r\n",
    "def calc_entropy(feature_value_data, label, class_list):\r\n",
    "    class_count = feature_value_data.shape[0]\r\n",
    "    entropy = 0\r\n",
    "    \r\n",
    "    for c in class_list:\r\n",
    "        label_class_count = feature_value_data[feature_value_data[label] == c].shape[0] #row count of class c \r\n",
    "        entropy_class = 0\r\n",
    "        if label_class_count != 0:\r\n",
    "            probability_class = label_class_count/class_count #probability of the class\r\n",
    "            entropy_class = - probability_class * np.log2(probability_class)  #entropy\r\n",
    "        entropy += entropy_class\r\n",
    "    return entropy"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "#function to calculate info gain \r\n",
    "def calc_info_gain(feature_name, train_data, label, class_list):\r\n",
    "    feature_value_list = train_data[feature_name].unique() #unqiue values of the feature\r\n",
    "    total_row = train_data.shape[0]\r\n",
    "    feature_info = 0.0\r\n",
    "    \r\n",
    "    for feature_value in feature_value_list:\r\n",
    "        feature_value_data = train_data[train_data[feature_name] == feature_value] #filtering rows with that feature_value\r\n",
    "        feature_value_count = feature_value_data.shape[0]\r\n",
    "        feature_value_entropy = calc_entropy(feature_value_data, label, class_list) #calculcating entropy for the feature value\r\n",
    "        feature_value_probability = feature_value_count/total_row\r\n",
    "        feature_info += feature_value_probability * feature_value_entropy #calculating information of the feature value\r\n",
    "        \r\n",
    "    return calc_total_entropy(train_data, label, class_list) - feature_info #calculating information gain by subtracting\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "#function to get the most informative feature\r\n",
    "def find_most_informative_feature(data, label, class_list):\r\n",
    "    feature_list = data.columns.drop(label) #finding the feature names in the dataset\r\n",
    "                                            #N.B. label is not a feature, so dropping it\r\n",
    "    max_info_gain = -1\r\n",
    "    max_info_feature = None\r\n",
    "    \r\n",
    "    for feature in feature_list:  #for each feature in the dataset\r\n",
    "        feature_info_gain = calc_info_gain(feature, data, label, class_list)\r\n",
    "        if max_info_gain < feature_info_gain: #selecting feature name with highest information gain\r\n",
    "            max_info_gain = feature_info_gain\r\n",
    "            max_info_feature = feature\r\n",
    "            \r\n",
    "    return max_info_feature #Return the feature with max info"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# function the get sub-tree (nodes)\r\n",
    "def generate_sub_tree(feature, train_data, label, class_list):\r\n",
    "    feature_value_count_dict = train_data[feature].value_counts(sort=False) #dictionary of the count of unqiue feature value\r\n",
    "    tree = {} #sub tree or node\r\n",
    "    \r\n",
    "    for feature_value, count in feature_value_count_dict.iteritems():\r\n",
    "        feature_value_data = train_data[train_data[feature] == feature_value] #dataset with only feature = feature_value\r\n",
    "        \r\n",
    "        assigned_to_node = False #flag for tracking feature_value is pure class or not\r\n",
    "        for c in class_list: #for each class\r\n",
    "            class_count = feature_value_data[feature_value_data[label] == c].shape[0] #count of class c\r\n",
    "\r\n",
    "            if class_count == count: #count of (feature_value = count) of class (pure class)\r\n",
    "                tree[feature_value] = c #adding node to the tree\r\n",
    "                train_data = train_data[train_data[feature] != feature_value] #removing rows with feature_value\r\n",
    "                assigned_to_node = True\r\n",
    "        if not assigned_to_node: #not pure class\r\n",
    "            tree[feature_value] = \"?\" #as feature_value is not a pure class, it should be expanded further, \r\n",
    "                                        #so the branch is marking with ?\r\n",
    "            \r\n",
    "    return tree, train_data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# now with the help of the previous functions , we generate the tree \r\n",
    "def make_tree(root, prev_feature_value, data, label, class_list):\r\n",
    "    if data.shape[0] != 0: #if dataset becomes enpty after updating\r\n",
    "        max_info_feature = find_most_informative_feature(data, label, class_list) #most informative feature\r\n",
    "        tree, train_data = generate_sub_tree(max_info_feature, data, label, class_list) #getting tree node and updated dataset\r\n",
    "        next_root = None\r\n",
    "        \r\n",
    "        if prev_feature_value != None: #add to intermediate node of the tree\r\n",
    "            root[prev_feature_value] = dict()\r\n",
    "            root[prev_feature_value][max_info_feature] = tree\r\n",
    "            next_root = root[prev_feature_value][max_info_feature]\r\n",
    "        else: #add to root of the tree\r\n",
    "            root[max_info_feature] = tree\r\n",
    "            next_root = root[max_info_feature]\r\n",
    "        \r\n",
    "        for node, branch in list(next_root.items()): #iterating the tree node\r\n",
    "            if branch == \"?\": #if it is expandable\r\n",
    "                feature_value_data = train_data[train_data[max_info_feature] == node] #using the updated dataset\r\n",
    "                make_tree(next_root, node, feature_value_data, label, class_list) #recursive call with updated dataset\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "#function to generate id3 tree\r\n",
    "def id3(train_data_m, label):\r\n",
    "    train_data = train_data_m.copy() #getting a copy of the dataset\r\n",
    "    tree = {} #tree which will be updated\r\n",
    "    class_list = train_data[label].unique() #getting unqiue classes of the label\r\n",
    "    make_tree(tree, None, train_data, label, class_list) #start calling recursion\r\n",
    "    return tree"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "tree = id3(df, 'diagnosis')\r\n",
    "print(tree)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#prediction function\r\n",
    "def predict(tree, instance):\r\n",
    "    if not isinstance(tree, dict): #if it is leaf node\r\n",
    "        return tree #return the value\r\n",
    "    else:\r\n",
    "        root_node = next(iter(tree)) #getting first key/feature name of the dictionary\r\n",
    "        feature_value = instance[root_node] #value of the feature\r\n",
    "        if feature_value in tree[root_node]: #checking the feature value in current tree node\r\n",
    "            return predict(tree[root_node][feature_value], instance) #goto next feature\r\n",
    "        else:\r\n",
    "            return None"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#function to do the final evaluation\r\n",
    "def evaluate(tree, test_data_m, label):\r\n",
    "    correct_preditct = 0\r\n",
    "    wrong_preditct = 0\r\n",
    "    for index, row in test_data_m.iterrows(): #for each row in the dataset\r\n",
    "        result = predict(tree, test_data_m.iloc[index]) #predict the row\r\n",
    "        if result == test_data_m[label].iloc[index]: #predicted value and expected value is same or not\r\n",
    "            correct_preditct += 1 #increase correct count\r\n",
    "        else:\r\n",
    "            wrong_preditct += 1 #increase incorrect count\r\n",
    "    accuracy = correct_preditct / (correct_preditct + wrong_preditct) #calculating accuracy\r\n",
    "    return accuracy"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "accuracy = evaluate(tree, df,'diagnosis') #evaluating the test dataset\r\n",
    "print(\"Your estimated accuracy is:\",accuracy)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.10.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.10.6 64-bit"
  },
  "interpreter": {
   "hash": "46f52deec83a59e7816093c53e4585ac88cc6d89b2339bf7f71bdff177af4833"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}